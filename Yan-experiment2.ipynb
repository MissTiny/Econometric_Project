{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8235645-3fe9-4963-9465-fe0b286d2f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as ax\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "from statsmodels.base.model import LikelihoodModel\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from scipy.stats import pearsonr\n",
    "import unicodedata\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns; sns.set()\n",
    "from linearmodels.iv import absorbing\n",
    "\n",
    "from linearmodels.datasets import wage_panel\n",
    "from linearmodels.panel import PanelOLS\n",
    "from linearmodels.iv.model import (\n",
    "    COVARIANCE_ESTIMATORS,\n",
    "    ClusteredCovariance,\n",
    "    HeteroskedasticCovariance,\n",
    "    HomoskedasticCovariance,\n",
    "    KernelCovariance,\n",
    ")\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99845b67-be4c-4ed0-a178-c81f0c1f4c81",
   "metadata": {},
   "source": [
    "## references\n",
    "https://stackoverflow.com/questions/70954911/results-from-python-linearmodels-panelols-and-stata-areg-differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69767f63-4a78-479c-b426-e9d794e1496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_stata('/Users/zyy219/Dropbox/Econometric/mksc.2021.1339/data/gdpr_website.dta')\n",
    "data = data[(data['date']<np.datetime64('2018-10-02')) & \n",
    "         (data['date']>np.datetime64('2017-11-14'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b7c7e0-4951-48a9-90c7-01241bea78e5",
   "metadata": {},
   "source": [
    "### Table 4 Change in Number of Requested Third-Party Domains and Cookies- EU firm & requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dd04c6a-90ea-469f-bdf3-23b1962d1601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dependent variable =  2.3778364658355713\n",
      "                         Absorbing LS Estimation Summary                          \n",
      "==================================================================================\n",
      "Dep. Variable:          log_requests3   R-squared:                          0.9120\n",
      "Estimator:               Absorbing LS   Adj. R-squared:                     0.9076\n",
      "No. Observations:              611919   F-statistic:                        164.82\n",
      "Date:                Sat, Dec 03 2022   P-value (F-stat):                   0.0000\n",
      "Time:                        16:17:03   Distribution:                  F(6,582774)\n",
      "Cov. Estimator:             clustered   R-squared (No Effects):             0.0078\n",
      "                                        Varaibles Absorbed:              2.914e+04\n",
      "                                     Parameter Estimates                                     \n",
      "=============================================================================================\n",
      "                           Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.3768     0.0041     577.26     0.0000      2.3687      2.3849\n",
      "trend_EU-audience             0.0082     0.0015     5.5588     0.0000      0.0053      0.0111\n",
      "trend_nonEU-audience          0.0019     0.0025     0.7338     0.4631     -0.0031      0.0068\n",
      "trend_post_EU-audience        0.0068     0.0027     2.5532     0.0107      0.0016      0.0120\n",
      "trend_post_nonEU-audience     0.0092     0.0042     2.1931     0.0283      0.0010      0.0175\n",
      "post_EU-audience             -0.0693     0.0024    -28.973     0.0000     -0.0740     -0.0646\n",
      "post_nonEU-audience          -0.0401     0.0034    -11.752     0.0000     -0.0468     -0.0334\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "def table4_1(data):\n",
    "    data['trend_EU-audience'] = data['trend']*data['eu_audience']\n",
    "    data['trend_nonEU-audience'] = data['trend']*data['noneu_audience']\n",
    "    data['post_EU-audience'] = data['after']*data['eu_audience']\n",
    "    data['post_nonEU-audience'] = data['after']*data['noneu_audience']\n",
    "    data['trend_post_EU-audience'] = data['trend_after']*data['after']*data['eu_audience']\n",
    "    data['trend_post_nonEU-audience'] = data['trend_after']*data['after']*data['noneu_audience']\n",
    "    D = data[data['eu_location'].isin([1])& data['exclude'].isin([0])]\n",
    "\n",
    "    cats = pd.DataFrame({'h': pd.Categorical(D['h'])})\n",
    "    exog_variables = ['trend_EU-audience','trend_nonEU-audience','trend_post_EU-audience',\n",
    "              'trend_post_nonEU-audience','post_EU-audience','post_nonEU-audience']\n",
    "    endog_variable = ['log_requests3']\n",
    "\n",
    "    exog = sm.tools.tools.add_constant(D[exog_variables])\n",
    "    endog = D[endog_variable]\n",
    "\n",
    "    model = absorbing.AbsorbingLS(endog, exog, absorb= cats, drop_absorbed=False)\n",
    "    model_res = model.fit(cov_type= 'clustered',clusters = D['h'],debiased=True)\n",
    "\n",
    "    print('Mean dependent variable = ',np.mean(D['log_requests3']))\n",
    "    print(model_res.summary)\n",
    "table4_1(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e2af0c-49c3-4265-81ea-3d561b8b1be8",
   "metadata": {},
   "source": [
    "### Table 4 Change in Number of Requested Third-Party Domains and Cookies-  non-EU firm & requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3635b28c-7c6d-44ee-970b-79041449b190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dependent variable =  2.4772861003875732\n",
      "                         Absorbing LS Estimation Summary                          \n",
      "==================================================================================\n",
      "Dep. Variable:          log_requests3   R-squared:                          0.9314\n",
      "Estimator:               Absorbing LS   Adj. R-squared:                     0.9280\n",
      "No. Observations:             1712907   F-statistic:                        192.40\n",
      "Date:                Sat, Dec 03 2022   P-value (F-stat):                   0.0000\n",
      "Time:                        16:17:24   Distribution:                 F(6,1631334)\n",
      "Cov. Estimator:             clustered   R-squared (No Effects):             0.0020\n",
      "                                        Varaibles Absorbed:              8.157e+04\n",
      "                                     Parameter Estimates                                     \n",
      "=============================================================================================\n",
      "                           Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.4327     0.0023     1037.4     0.0000      2.4281      2.4373\n",
      "trend_EU-audience             0.0131     0.0019     6.8873     0.0000      0.0094      0.0169\n",
      "trend_nonEU-audience          0.0130     0.0008     16.353     0.0000      0.0115      0.0146\n",
      "trend_post_EU-audience        0.0023     0.0033     0.7069     0.4796     -0.0042      0.0088\n",
      "trend_post_nonEU-audience     0.0099     0.0013     7.3425     0.0000      0.0073      0.0125\n",
      "post_EU-audience             -0.0395     0.0025    -15.513     0.0000     -0.0445     -0.0345\n",
      "post_nonEU-audience          -0.0150     0.0009    -16.346     0.0000     -0.0168     -0.0132\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "def table4_2(data):\n",
    "    data['trend_EU-audience'] = data['trend']*data['eu_audience']\n",
    "    data['trend_nonEU-audience'] = data['trend']*data['noneu_audience']\n",
    "    data['post_EU-audience'] = data['after']*data['eu_audience']\n",
    "    data['post_nonEU-audience'] = data['after']*data['noneu_audience']\n",
    "    data['trend_post_EU-audience'] = data['trend_after']*data['after']*data['eu_audience']\n",
    "    data['trend_post_nonEU-audience'] = data['trend_after']*data['after']*data['noneu_audience']\n",
    "    D = data[data['eu_location'].isin([0])& data['exclude'].isin([0])]\n",
    "    cats = pd.DataFrame({'h': pd.Categorical(D['h'])})\n",
    "    exog_variables = ['trend_EU-audience','trend_nonEU-audience','trend_post_EU-audience',\n",
    "              'trend_post_nonEU-audience','post_EU-audience','post_nonEU-audience']\n",
    "    endog_variable = ['log_requests3']\n",
    "\n",
    "    exog = sm.tools.tools.add_constant(D[exog_variables])\n",
    "    endog = D[endog_variable]\n",
    "\n",
    "    model = absorbing.AbsorbingLS(endog, exog, absorb= cats, drop_absorbed=False)\n",
    "    model_res = model.fit(cov_type= 'clustered',clusters = D['h'], debiased=True)\n",
    "    print('Mean dependent variable = ',np.mean(D['log_requests3']))\n",
    "    print(model_res.summary)\n",
    "table4_2(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e160e4-e9a4-4b5b-a815-67fc715f32ad",
   "metadata": {},
   "source": [
    "### Table 4 Change in Number of Requested Third-Party Domains and Cookies-  EU firm & cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f292a00-13cc-42b1-bf1b-02c6e1d731e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Absorbing LS Estimation Summary                          \n",
      "==================================================================================\n",
      "Dep. Variable:           log_cookies3   R-squared:                          0.8801\n",
      "Estimator:               Absorbing LS   Adj. R-squared:                     0.8741\n",
      "No. Observations:              611919   F-statistic:                        247.79\n",
      "Date:                Sat, Dec 03 2022   P-value (F-stat):                   0.0000\n",
      "Time:                        16:17:47   Distribution:                  F(6,582774)\n",
      "Cov. Estimator:             clustered   R-squared (No Effects):             0.0135\n",
      "                                        Varaibles Absorbed:              2.914e+04\n",
      "                                     Parameter Estimates                                     \n",
      "=============================================================================================\n",
      "                           Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.3628     0.0059     230.08     0.0000      1.3512      1.3744\n",
      "trend_EU-audience             0.0111     0.0021     5.1894     0.0000      0.0069      0.0152\n",
      "trend_nonEU-audience          0.0090     0.0038     2.3886     0.0169      0.0016      0.0164\n",
      "trend_post_EU-audience        0.0003     0.0037     0.0708     0.9436     -0.0071      0.0076\n",
      "trend_post_nonEU-audience    -0.0034     0.0062    -0.5540     0.5796     -0.0156      0.0087\n",
      "post_EU-audience             -0.1133     0.0033    -34.288     0.0000     -0.1198     -0.1069\n",
      "post_nonEU-audience          -0.0747     0.0046    -16.383     0.0000     -0.0836     -0.0657\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "def table4_3(data):\n",
    "    data['trend_EU-audience'] = data['trend']*data['eu_audience']\n",
    "    data['trend_nonEU-audience'] = data['trend']*data['noneu_audience']\n",
    "    data['post_EU-audience'] = data['after']*data['eu_audience']\n",
    "    data['post_nonEU-audience'] = data['after']*data['noneu_audience']\n",
    "    data['trend_post_EU-audience'] = data['trend_after']*data['after']*data['eu_audience']\n",
    "    data['trend_post_nonEU-audience'] = data['trend_after']*data['after']*data['noneu_audience']\n",
    "    D = data[data['eu_location'].isin([1])& data['exclude'].isin([0])]\n",
    "    cats = pd.DataFrame({'h': pd.Categorical(D['h'])})\n",
    "\n",
    "    exog_variables = ['trend_EU-audience','trend_nonEU-audience','trend_post_EU-audience',\n",
    "              'trend_post_nonEU-audience','post_EU-audience','post_nonEU-audience']\n",
    "    endog_variable = ['log_cookies3']\n",
    "\n",
    "    exog = sm.tools.tools.add_constant(D[exog_variables])\n",
    "    endog = D[endog_variable]\n",
    "\n",
    "    model = absorbing.AbsorbingLS(endog, exog, absorb= cats, drop_absorbed=False)\n",
    "    model_res = model.fit(cov_type= 'clustered',clusters = D['h'], debiased=True)\n",
    "    #print(np.mean(Y))\n",
    "    print(model_res.summary)\n",
    "table4_3(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a15b5c-c819-4e17-a650-708c1c02af9f",
   "metadata": {},
   "source": [
    "### Table 4 Change in Number of Requested Third-Party Domains and Cookies-  non-EU firm & cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6316c8bf-66f1-4c86-8b46-93c0605c7312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Absorbing LS Estimation Summary                          \n",
      "==================================================================================\n",
      "Dep. Variable:           log_cookies3   R-squared:                          0.9023\n",
      "Estimator:               Absorbing LS   Adj. R-squared:                     0.8974\n",
      "No. Observations:             1712907   F-statistic:                        313.42\n",
      "Date:                Sat, Dec 03 2022   P-value (F-stat):                   0.0000\n",
      "Time:                        16:18:04   Distribution:                 F(6,1631334)\n",
      "Cov. Estimator:             clustered   R-squared (No Effects):             0.0024\n",
      "                                        Varaibles Absorbed:              8.157e+04\n",
      "                                     Parameter Estimates                                     \n",
      "=============================================================================================\n",
      "                           Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.3755     0.0035     397.40     0.0000      1.3688      1.3823\n",
      "trend_EU-audience             0.0191     0.0028     6.8422     0.0000      0.0137      0.0246\n",
      "trend_nonEU-audience          0.0272     0.0012     23.011     0.0000      0.0249      0.0295\n",
      "trend_post_EU-audience       -0.0108     0.0049    -2.2060     0.0274     -0.0203     -0.0012\n",
      "trend_post_nonEU-audience    -0.0068     0.0020    -3.4771     0.0005     -0.0106     -0.0030\n",
      "post_EU-audience             -0.0804     0.0037    -21.739     0.0000     -0.0877     -0.0732\n",
      "post_nonEU-audience          -0.0446     0.0013    -33.958     0.0000     -0.0472     -0.0420\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "def table4_4(data):\n",
    "    data['trend_EU-audience'] = data['trend']*data['eu_audience']\n",
    "    data['trend_nonEU-audience'] = data['trend']*data['noneu_audience']\n",
    "    data['post_EU-audience'] = data['after']*data['eu_audience']\n",
    "    data['post_nonEU-audience'] = data['after']*data['noneu_audience']\n",
    "    data['trend_post_EU-audience'] = data['trend_after']*data['after']*data['eu_audience']\n",
    "    data['trend_post_nonEU-audience'] = data['trend_after']*data['after']*data['noneu_audience']\n",
    "    D = data[data['eu_location'].isin([0])& data['exclude'].isin([0])]\n",
    "    cats = pd.DataFrame({'h': pd.Categorical(D['h'])})\n",
    "\n",
    "    exog_variables = ['trend_EU-audience','trend_nonEU-audience','trend_post_EU-audience',\n",
    "              'trend_post_nonEU-audience','post_EU-audience','post_nonEU-audience']\n",
    "    endog_variable = ['log_cookies3']\n",
    "\n",
    "    exog = sm.tools.tools.add_constant(D[exog_variables])\n",
    "    endog = D[endog_variable]\n",
    "\n",
    "    model = absorbing.AbsorbingLS(endog, exog, absorb= cats, drop_absorbed=False)\n",
    "    model_res = model.fit(cov_type= 'clustered',clusters = D['h'], debiased=True)\n",
    "    print(model_res.summary)\n",
    "table4_4(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ecb5e-ef7d-4602-ac6f-c93a66428f3e",
   "metadata": {},
   "source": [
    "### Table 5 Change in Number of Requested Third-Party Domains and Cookies: Website Popularity- EU firm & requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3a9b8df-466b-4daf-a1b5-fab503d19720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Absorbing LS Estimation Summary                          \n",
      "==================================================================================\n",
      "Dep. Variable:          log_requests3   R-squared:                          0.9119\n",
      "Estimator:               Absorbing LS   Adj. R-squared:                     0.9075\n",
      "No. Observations:              611541   F-statistic:                        123.91\n",
      "Date:                Sat, Dec 03 2022   P-value (F-stat):                   0.0000\n",
      "Time:                        16:18:37   Distribution:                  F(8,582412)\n",
      "Cov. Estimator:             clustered   R-squared (No Effects):             0.0079\n",
      "                                        Varaibles Absorbed:              2.912e+04\n",
      "                                     Parameter Estimates                                     \n",
      "=============================================================================================\n",
      "                           Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.3769     0.0041     576.99     0.0000      2.3689      2.3850\n",
      "trend_EU-audience             0.0082     0.0015     5.5519     0.0000      0.0053      0.0111\n",
      "trend_nonEU-audience          0.0019     0.0025     0.7426     0.4577     -0.0031      0.0068\n",
      "trend_post_EU-audience        0.0068     0.0027     2.5678     0.0102      0.0016      0.0121\n",
      "trend_post_nonEU-audience     0.0092     0.0042     2.1934     0.0283      0.0010      0.0175\n",
      "post_EU-audience             -0.0696     0.0024    -28.990     0.0000     -0.0743     -0.0649\n",
      "post_nonEU-audience          -0.0402     0.0034    -11.758     0.0000     -0.0469     -0.0335\n",
      "post_EU-audience_top          0.0539     0.0276     1.9528     0.0508     -0.0002      0.1081\n",
      "post_nonEU-audience_top      -0.0454     0.1193    -0.3803     0.7037     -0.2792      0.1884\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "def table5_1(data):\n",
    "    data['post_EU-audience_top'] = data['after']*data['eu_audience']*data['top']\n",
    "    data['post_nonEU-audience_top'] = data['after']*data['noneu_audience']*data['top']\n",
    "    D = data[data['top'].isin([0,1]) & data['eu_location'].isin([1])& data['exclude'].isin([0])]\n",
    "    cats = pd.DataFrame({'h': pd.Categorical(D['h'])})\n",
    "    endog_variable = ['log_requests3']\n",
    "    exog_variables = ['trend_EU-audience','trend_nonEU-audience','trend_post_EU-audience',\n",
    "          'trend_post_nonEU-audience','post_EU-audience','post_nonEU-audience',\n",
    "          'post_EU-audience_top','post_nonEU-audience_top']\n",
    "    exog = sm.tools.tools.add_constant(D[exog_variables])\n",
    "    endog = D[endog_variable]\n",
    "\n",
    "    model = absorbing.AbsorbingLS(endog, exog, absorb= cats, drop_absorbed=False)\n",
    "    model_res = model.fit(cov_type= 'clustered',clusters = D['h'], debiased=True)\n",
    "    print(model_res.summary)\n",
    "table5_1(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c605001-93e4-40c1-bd9b-49685d307231",
   "metadata": {},
   "source": [
    "### Table 5 Change in Number of Requested Third-Party Domains and Cookies: Website Popularity- non-EU firm & requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e06cb887-016d-41a9-8e06-7b810808271b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Absorbing LS Estimation Summary                          \n",
      "==================================================================================\n",
      "Dep. Variable:          log_requests3   R-squared:                          0.9314\n",
      "Estimator:               Absorbing LS   Adj. R-squared:                     0.9280\n",
      "No. Observations:             1711374   F-statistic:                        144.67\n",
      "Date:                Sat, Dec 03 2022   P-value (F-stat):                   0.0000\n",
      "Time:                        16:18:44   Distribution:                 F(8,1629872)\n",
      "Cov. Estimator:             clustered   R-squared (No Effects):             0.0021\n",
      "                                        Varaibles Absorbed:              8.149e+04\n",
      "                                     Parameter Estimates                                     \n",
      "=============================================================================================\n",
      "                           Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         2.4330     0.0023     1037.0     0.0000      2.4284      2.4376\n",
      "trend_EU-audience             0.0131     0.0019     6.8622     0.0000      0.0094      0.0168\n",
      "trend_nonEU-audience          0.0130     0.0008     16.360     0.0000      0.0115      0.0146\n",
      "trend_post_EU-audience        0.0024     0.0033     0.7152     0.4745     -0.0041      0.0089\n",
      "trend_post_nonEU-audience     0.0099     0.0013     7.3602     0.0000      0.0073      0.0126\n",
      "post_EU-audience             -0.0405     0.0026    -15.503     0.0000     -0.0456     -0.0353\n",
      "post_nonEU-audience          -0.0151     0.0009    -16.397     0.0000     -0.0169     -0.0133\n",
      "post_EU-audience_top          0.0381     0.0137     2.7728     0.0056      0.0112      0.0650\n",
      "post_nonEU-audience_top       0.0334     0.0252     1.3233     0.1857     -0.0161      0.0828\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "def table5_2(data):\n",
    "    data['post_EU-audience_top'] = data['after']*data['eu_audience']*data['top']\n",
    "    data['post_nonEU-audience_top'] = data['after']*data['noneu_audience']*data['top']\n",
    "    D = data[data['top'].isin([0,1]) & data['eu_location'].isin([0])& data['exclude'].isin([0])]\n",
    "    cats = pd.DataFrame({'h': pd.Categorical(D['h'])})\n",
    "    endog_variable = ['log_requests3']\n",
    "    exog_variables = ['trend_EU-audience','trend_nonEU-audience','trend_post_EU-audience',\n",
    "              'trend_post_nonEU-audience','post_EU-audience','post_nonEU-audience',\n",
    "              'post_EU-audience_top','post_nonEU-audience_top']\n",
    "\n",
    "    exog = sm.tools.tools.add_constant(D[exog_variables])\n",
    "    endog = D[endog_variable]\n",
    "\n",
    "    model = absorbing.AbsorbingLS(endog, exog, absorb= cats, drop_absorbed=False)\n",
    "    model_res = model.fit(cov_type= 'clustered',clusters = D['h'], debiased=True)\n",
    "    print(model_res.summary)\n",
    "table5_2(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85690c89-9d92-4c7b-9486-7046a40fa3ee",
   "metadata": {},
   "source": [
    "### Table 5 Change in Number of Requested Third-Party Domains and Cookies: Website Popularity- EU firm & cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "250c9c91-4448-4ad4-8f5b-983b4ff62c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Absorbing LS Estimation Summary                          \n",
      "==================================================================================\n",
      "Dep. Variable:           log_cookies3   R-squared:                          0.8801\n",
      "Estimator:               Absorbing LS   Adj. R-squared:                     0.8741\n",
      "No. Observations:              611541   F-statistic:                        186.06\n",
      "Date:                Sat, Dec 03 2022   P-value (F-stat):                   0.0000\n",
      "Time:                        16:18:53   Distribution:                  F(8,582412)\n",
      "Cov. Estimator:             clustered   R-squared (No Effects):             0.0135\n",
      "                                        Varaibles Absorbed:              2.912e+04\n",
      "                                     Parameter Estimates                                     \n",
      "=============================================================================================\n",
      "                           Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.3629     0.0059     229.99     0.0000      1.3513      1.3745\n",
      "trend_EU-audience             0.0111     0.0021     5.1855     0.0000      0.0069      0.0152\n",
      "trend_nonEU-audience          0.0090     0.0038     2.3819     0.0172      0.0016      0.0164\n",
      "trend_post_EU-audience        0.0003     0.0037     0.0822     0.9345     -0.0070      0.0077\n",
      "trend_post_nonEU-audience    -0.0034     0.0062    -0.5447     0.5860     -0.0156      0.0088\n",
      "post_EU-audience             -0.1136     0.0033    -34.248     0.0000     -0.1201     -0.1071\n",
      "post_nonEU-audience          -0.0748     0.0046    -16.392     0.0000     -0.0837     -0.0658\n",
      "post_EU-audience_top          0.0360     0.0371     0.9686     0.3328     -0.0368      0.1088\n",
      "post_nonEU-audience_top       0.0452     0.1293     0.3498     0.7265     -0.2082      0.2987\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "def table5_3(data):\n",
    "    data['post_EU-audience_top'] = data['after']*data['eu_audience']*data['top']\n",
    "    data['post_nonEU-audience_top'] = data['after']*data['noneu_audience']*data['top']\n",
    "    D = data[data['top'].isin([0,1]) & data['eu_location'].isin([1])& data['exclude'].isin([0])]\n",
    "    cats = pd.DataFrame({'h': pd.Categorical(D['h'])})\n",
    "    endog_variable = ['log_cookies3']\n",
    "    exog_variables = ['trend_EU-audience','trend_nonEU-audience','trend_post_EU-audience',\n",
    "              'trend_post_nonEU-audience','post_EU-audience','post_nonEU-audience',\n",
    "              'post_EU-audience_top','post_nonEU-audience_top']\n",
    "\n",
    "    exog = sm.tools.tools.add_constant(D[exog_variables])\n",
    "    endog = D[endog_variable]\n",
    "\n",
    "    model = absorbing.AbsorbingLS(endog, exog, absorb= cats, drop_absorbed=False)\n",
    "    model_res = model.fit(cov_type= 'clustered',clusters = D['h'], debiased=True)\n",
    "    print(model_res.summary)\n",
    "table5_3(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a7b06-ddc6-4bf6-83cb-449146788b74",
   "metadata": {},
   "source": [
    "### Table 5 Change in Number of Requested Third-Party Domains and Cookies: Website Popularity- non-EU firm & cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b870f9b9-809e-4c2a-944f-a235a959abee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Absorbing LS Estimation Summary                          \n",
      "==================================================================================\n",
      "Dep. Variable:           log_cookies3   R-squared:                          0.9023\n",
      "Estimator:               Absorbing LS   Adj. R-squared:                     0.8974\n",
      "No. Observations:             1711374   F-statistic:                        235.51\n",
      "Date:                Sat, Dec 03 2022   P-value (F-stat):                   0.0000\n",
      "Time:                        16:19:04   Distribution:                 F(8,1629872)\n",
      "Cov. Estimator:             clustered   R-squared (No Effects):             0.0024\n",
      "                                        Varaibles Absorbed:              8.149e+04\n",
      "                                     Parameter Estimates                                     \n",
      "=============================================================================================\n",
      "                           Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.3758     0.0035     397.31     0.0000      1.3690      1.3826\n",
      "trend_EU-audience             0.0192     0.0028     6.8406     0.0000      0.0137      0.0247\n",
      "trend_nonEU-audience          0.0273     0.0012     23.048     0.0000      0.0249      0.0296\n",
      "trend_post_EU-audience       -0.0108     0.0049    -2.2175     0.0266     -0.0204     -0.0013\n",
      "trend_post_nonEU-audience    -0.0068     0.0020    -3.4755     0.0005     -0.0106     -0.0030\n",
      "post_EU-audience             -0.0817     0.0038    -21.555     0.0000     -0.0892     -0.0743\n",
      "post_nonEU-audience          -0.0447     0.0013    -33.976     0.0000     -0.0473     -0.0421\n",
      "post_EU-audience_top          0.0470     0.0201     2.3368     0.0194      0.0076      0.0864\n",
      "post_nonEU-audience_top       0.0277     0.0299     0.9267     0.3541     -0.0309      0.0864\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "def table5_4(data):\n",
    "    data['post_EU-audience_top'] = data['after']*data['eu_audience']*data['top']\n",
    "    data['post_nonEU-audience_top'] = data['after']*data['noneu_audience']*data['top']\n",
    "    D = data[data['top'].isin([0,1]) & data['eu_location'].isin([0])& data['exclude'].isin([0])]\n",
    "    cats = pd.DataFrame({'h': pd.Categorical(D['h'])})\n",
    "    endog_variable = ['log_cookies3']\n",
    "    exog_variables = ['trend_EU-audience','trend_nonEU-audience','trend_post_EU-audience',\n",
    "              'trend_post_nonEU-audience','post_EU-audience','post_nonEU-audience',\n",
    "              'post_EU-audience_top','post_nonEU-audience_top']\n",
    "\n",
    "    exog = sm.tools.tools.add_constant(D[exog_variables])\n",
    "    endog = D[endog_variable]\n",
    "\n",
    "    model = absorbing.AbsorbingLS(endog, exog, absorb= cats, drop_absorbed=False)\n",
    "    model_res = model.fit(cov_type= 'clustered',clusters = D['h'], debiased=True)\n",
    "    print(model_res.summary)\n",
    "table5_4(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd4ce6-affa-4003-9d99-35bd07da3021",
   "metadata": {},
   "source": [
    "### Table 6 Change in Websites Served by Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "266a240d-23ae-4db9-874a-e146f36ea9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table6(data,data_policy):\n",
    "    data = data[data['exclude']==0]\n",
    "    D = data.merge(data_policy, on='tracker', how='left') #after drop if _merge ==2\n",
    "    DD = data.merge(data_policy, how='inner', on='tracker') #find _merge = 3\n",
    "    _merge3 = DD['tracker'].unique().tolist()\n",
    "    m = []\n",
    "    for i in range(len(D)):\n",
    "        if D['tracker'][i] in _merge3:\n",
    "             m.append(1)\n",
    "        else:\n",
    "             m.append(0)\n",
    "    D['m'] = m\n",
    "    #bys tracker_firm: egen temp=max(m) keep if temp==1\n",
    "    D_agg = D.groupby(['tracker_firm'],as_index=False).agg({'m': ['max']}) #bys tracker_firm: egen temp=max(m)\n",
    "    D_sorted = D[D['tracker_firm'].isin(D_agg[D_agg['m']['max']==1]['tracker_firm'].tolist())] #keep if temp = 1\n",
    "    D_sorted1 = D_sorted.groupby(['tracker_firm','date'],as_index=False).agg(date=('date','first'),shr_undisclosed = ('shr_undisclosed','max'),\n",
    "                        shr_aggregate = ('shr_aggregate','max'),shr_anonymous = ('shr_anonymous','max'),shr_pseudo = ('shr_pseudo','max'),\n",
    "                        shr_pii = ('shr_pii','max'),shr_sensitive = ('shr_sensitive','max'),\n",
    "                        col_undisclosed = ('col_undisclosed','max'), col_anonymous = ('col_anonymous','max'),col_pseudo = ('col_pseudo','max'), col_pii = ('col_pii','max'),\n",
    "                        col_sensitive = ('col_sensitive','max'),\n",
    "                        use_undisclosed = ('use_undisclosed','max'),\n",
    "                        use_analytics = ('use_analytics','max'),\n",
    "                        use_ad = ('use_ad','max'),\n",
    "                        use_custom = ('use_custom','max'),\n",
    "                        use_optimization = ('use_optimization','max'),\n",
    "                        use_tracking = ('use_tracking','max'),\n",
    "                                                                         \n",
    "                        retention = ('retention','max'),\n",
    "                        websites=('websites','sum'),\n",
    "                        websites_cookie=('websites','sum'),\n",
    "                        totalwebsites=('totalwebsites','mean'))\n",
    "    D_sorted1['ms_websites_firm'] = D_sorted1['websites']/D_sorted1['totalwebsites']*100 #gen ms_websites_firm=(websites/totalwebsites)*100\n",
    "    D_sorted1['ms_websites_cookie_firm'] = D_sorted1['websites_cookie']/D_sorted1['totalwebsites']*100 #gen ms_websites_cookie_firm=(websites_cookie/totalwebsites)*100\n",
    "\n",
    "    D_sorted1['post']=np.where(D_sorted1['date']>np.datetime64('2018-05-25'), 1,0 )\n",
    "    D_sorted1['trend']=(D_sorted1['date']- D_sorted1['date'].min()+np.timedelta64(1, 'D'))/np.timedelta64(100, 'D')\n",
    "    D_sorted1['col_personal_post']=D_sorted1['post']*D_sorted1['col_pii']\n",
    "    D_sorted1['shr_personal_post']=D_sorted1['post']*D_sorted1['shr_pii']\n",
    "    D_sorted1['shr_col_personal_post']=D_sorted1['post']*D_sorted1['shr_pii']*D_sorted1['col_pii']\n",
    "    D_sorted1['col_personal_trend']=D_sorted1['trend']*D_sorted1['col_pii']\n",
    "    D_sorted1['shr_personal_trend']=D_sorted1['trend']*D_sorted1['shr_pii']\n",
    "    D_sorted1['shr_col_personal_trend']=D_sorted1['trend']*D_sorted1['shr_pii']*D_sorted1['col_pii']\n",
    "    D_sorted1['tf']=D_sorted1.groupby('tracker_firm').ngroup()\n",
    "    D_sorted1['log_websites']=np.log(1+D_sorted1['websites'])\n",
    "    D_sorted1['log_websites_cookie']=np.log(1+D_sorted1['websites_cookie'])\n",
    "\n",
    "    cats = pd.DataFrame({'tf': pd.Categorical(D_sorted1['tf'])})\n",
    "    endog = D_sorted1['log_websites']\n",
    "    exog = sm.tools.tools.add_constant(D_sorted1[['post','col_personal_post','trend','col_personal_trend']])\n",
    "    model = absorbing.AbsorbingLS(endog, exog, absorb= cats, drop_absorbed=False)\n",
    "    model_res = model.fit(cov_type= 'clustered',clusters = D_sorted1['tf'], debiased=True)\n",
    "    print(model_res.summary)\n",
    "    \n",
    "    exog = sm.tools.tools.add_constant(D_sorted1[['post','col_personal_post','shr_personal_post','trend','col_personal_trend','shr_personal_trend']])\n",
    "    model = absorbing.AbsorbingLS(endog, exog, absorb= cats, drop_absorbed=False)\n",
    "    model_res = model.fit(cov_type= 'clustered',clusters = D_sorted1['tf'], debiased=True)\n",
    "    print(model_res.summary)\n",
    "    \n",
    "    exog = sm.tools.tools.add_constant(D_sorted1[['post','col_personal_post','shr_personal_post','shr_col_personal_post',\n",
    "                                                  'trend','col_personal_trend','shr_personal_trend',\n",
    "                                                  'shr_col_personal_trend']])\n",
    "    model = absorbing.AbsorbingLS(endog, exog, absorb= cats, drop_absorbed=False)\n",
    "    model_res = model.fit(cov_type= 'clustered',clusters = D_sorted1['tf'], debiased=True)\n",
    "    print(model_res.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0aa81b2-2d22-41e1-bdd8-218d9e00e25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Absorbing LS Estimation Summary                          \n",
      "==================================================================================\n",
      "Dep. Variable:           log_websites   R-squared:                          0.9682\n",
      "Estimator:               Absorbing LS   Adj. R-squared:                     0.9665\n",
      "No. Observations:               42820   F-statistic:                        5.4050\n",
      "Date:                Sat, Dec 03 2022   P-value (F-stat):                   0.0002\n",
      "Time:                        16:21:24   Distribution:                   F(4,40675)\n",
      "Cov. Estimator:             clustered   R-squared (No Effects):             0.0051\n",
      "                                        Varaibles Absorbed:                 2140.0\n",
      "                                 Parameter Estimates                                  \n",
      "======================================================================================\n",
      "                    Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  2.7458     0.0117     233.96     0.0000      2.7228      2.7688\n",
      "post                  -0.0066     0.0121    -0.5457     0.5853     -0.0303      0.0171\n",
      "col_personal_post     -0.0109     0.0176    -0.6176     0.5368     -0.0453      0.0236\n",
      "trend                 -0.0386     0.0100    -3.8762     0.0001     -0.0582     -0.0191\n",
      "col_personal_trend     0.0237     0.0138     1.7228     0.0849     -0.0033      0.0508\n",
      "======================================================================================\n",
      "                         Absorbing LS Estimation Summary                          \n",
      "==================================================================================\n",
      "Dep. Variable:           log_websites   R-squared:                          0.9682\n",
      "Estimator:               Absorbing LS   Adj. R-squared:                     0.9665\n",
      "No. Observations:               42820   F-statistic:                        4.3863\n",
      "Date:                Sat, Dec 03 2022   P-value (F-stat):                   0.0002\n",
      "Time:                        16:21:24   Distribution:                   F(6,40673)\n",
      "Cov. Estimator:             clustered   R-squared (No Effects):             0.0055\n",
      "                                        Varaibles Absorbed:                 2140.0\n",
      "                                 Parameter Estimates                                  \n",
      "======================================================================================\n",
      "                    Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  2.7458     0.0117     233.99     0.0000      2.7228      2.7688\n",
      "post                  -0.0079     0.0121    -0.6510     0.5150     -0.0315      0.0158\n",
      "col_personal_post     -0.0260     0.0196    -1.3289     0.1839     -0.0644      0.0124\n",
      "shr_personal_post      0.0421     0.0259     1.6252     0.1041     -0.0087      0.0928\n",
      "trend                 -0.0387     0.0100    -3.8735     0.0001     -0.0583     -0.0191\n",
      "col_personal_trend     0.0231     0.0146     1.5851     0.1129     -0.0055      0.0517\n",
      "shr_personal_trend     0.0017     0.0193     0.0898     0.9284     -0.0361      0.0395\n",
      "======================================================================================\n",
      "                         Absorbing LS Estimation Summary                          \n",
      "==================================================================================\n",
      "Dep. Variable:           log_websites   R-squared:                          0.9682\n",
      "Estimator:               Absorbing LS   Adj. R-squared:                     0.9665\n",
      "No. Observations:               42820   F-statistic:                        3.3022\n",
      "Date:                Sat, Dec 03 2022   P-value (F-stat):                   0.0009\n",
      "Time:                        16:21:24   Distribution:                   F(8,40671)\n",
      "Cov. Estimator:             clustered   R-squared (No Effects):             0.0056\n",
      "                                        Varaibles Absorbed:                 2140.0\n",
      "                                   Parameter Estimates                                    \n",
      "==========================================================================================\n",
      "                        Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      2.7458     0.0117     233.99     0.0000      2.7228      2.7688\n",
      "post                      -0.0069     0.0120    -0.5721     0.5672     -0.0305      0.0167\n",
      "col_personal_post         -0.0280     0.0198    -1.4153     0.1570     -0.0667      0.0108\n",
      "shr_personal_post          0.0097     0.1041     0.0934     0.9256     -0.1943      0.2137\n",
      "shr_col_personal_post      0.0349     0.1074     0.3245     0.7455     -0.1757      0.2455\n",
      "trend                     -0.0398     0.0101    -3.9257     0.0001     -0.0597     -0.0199\n",
      "col_personal_trend         0.0254     0.0151     1.6830     0.0924     -0.0042      0.0550\n",
      "shr_personal_trend         0.0396     0.0532     0.7438     0.4570     -0.0647      0.1439\n",
      "shr_col_personal_trend    -0.0408     0.0570    -0.7158     0.4741     -0.1525      0.0709\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "data_policy = pd.read_stata('/Users/zyy219/Dropbox/Econometric/mksc.2021.1339/data/policies_before.dta') #each tracker only has one entry\n",
    "data = pd.read_stata('/Users/zyy219/Dropbox/Econometric/mksc.2021.1339/data/gdpr_vendors.dta')\n",
    "data = data[(data['date']<np.datetime64('2018-10-02')) & \n",
    "         (data['date']>np.datetime64('2017-11-14'))]\n",
    "table6(data,data_policy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ab19bec-d1be-4a93-94ee-78ae9faf86ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table7(dgpr_vendors):\n",
    "    # ------------------------------------------------\n",
    "    # This function will take dgpr_vendors dataset and output the table (7) to show the change in Market Structure \n",
    "    # of the Web Technology Industry\n",
    "    # Inputs: \n",
    "    #    dgpr_vendors dataset: dataset\n",
    "    # Output: Table 7\n",
    "    # ---------------------------------------------------\n",
    "    \n",
    "    \n",
    "    # bys tracker_firm date: keep if _n==1\n",
    "    result_table={}\n",
    "    result_table[\"row_name\"]=[\"After\",\"(std err)\",\"Observations\",\"Pre-GDPR mean\"]\n",
    "    \n",
    "    \n",
    "    ## ---------------------- HHI All--------------------------------\n",
    "    # collapse (sum) ms_websites_firm=ms_websites, by (tracker_firm date) fast\n",
    "    dgpr_vendors1 = dgpr_vendors.groupby(['tracker_firm','date'],as_index=False).agg(date=('date','first'),\n",
    "                                                                tracker_firm=('tracker_firm','first'),\n",
    "                                                                ms_websites_firm=('ms_websites','sum'))\n",
    "    # gen ms_websites_firm2=ms_websites_firm^2\n",
    "    dgpr_vendors1['ms_websites_firm2'] = dgpr_vendors1['ms_websites_firm']**2\n",
    "    \n",
    "    # collapse (sum) hhi=ms_websites_firm2, by (date) fast\n",
    "    dgpr_vendors2 = dgpr_vendors1.groupby(['date'],as_index=False).agg(date=('date','first'),\n",
    "                                                                    hhi=('ms_websites_firm2','sum'))\n",
    "\n",
    "    # gen after=date>td(25may2018)\n",
    "    dgpr_vendors2['after']=np.where(dgpr_vendors2['date']>np.datetime64('2018-05-25'), 1,0 )\n",
    "    \n",
    "    # su date\n",
    "    # gen trend=(date-r(min)+1)/100\n",
    "    dgpr_vendors2['trend']=(dgpr_vendors2['date']- dgpr_vendors2['date'].min()+np.timedelta64(1, 'D'))/np.timedelta64(100, 'D')\n",
    "    \n",
    "    # su date if after==1\n",
    "    # gen trend_after=(date-r(min)+1)/100\n",
    "    dgpr_vendors2['trend_after']=0\n",
    "    dgpr_vendors2.loc[dgpr_vendors2['after']==1,'trend_after']=(dgpr_vendors2.loc[\n",
    "        dgpr_vendors2['after']==1,'date']-dgpr_vendors2.loc[dgpr_vendors2['after']==1,'date'].min()+\n",
    "                                                                np.timedelta64(1, 'D'))/np.timedelta64(100, 'D')\n",
    "    \n",
    "    # eststo m_requests_g: reg hhi trend after c.trend_after#c.after, robust\n",
    "    m_requests_g_all = smf.ols(\"hhi ~ trend + after + trend_after*after\", data=dgpr_vendors2).fit(cov_type='HC1')\n",
    "    m_requests_g_all.summary().tables[1]\n",
    "    result_for_all = pd.read_html(m_requests_g_all.summary().tables[1].as_html(), header=0, index_col=0)[0]\n",
    "    result_table[\"HHI all\"]=[result_for_all.loc[\"after\",\"coef\"].round(3),result_for_all.loc[\"after\",\"std err\"].round(3),\n",
    "                             f\"{len(dgpr_vendors2)}\",round(dgpr_vendors2[dgpr_vendors2['after']==0][\"hhi\"].mean(),3) ]\n",
    "    \n",
    "    \n",
    "    ## ---------------------- HHI without Google--------------------------------\n",
    "    \n",
    "    # drop if tracker_firm==\"google\"\n",
    "    dgpr_vendors_nonGoogle=dgpr_vendors[dgpr_vendors[\"tracker_firm\"]!=\"google\"]\n",
    "    # collapse (sum) ms_websites_firm=ms_websites, by (tracker_firm date) fast\n",
    "    dgpr_vendors3 = dgpr_vendors_nonGoogle.groupby(['tracker_firm','date'],as_index=False).agg(date=('date','first'),\n",
    "                                                                tracker_firm=('tracker_firm','first'),\n",
    "                                                                ms_websites_firm=('ms_websites','sum'))\n",
    "    # gen ms_websites_firm2=ms_websites_firm^2\n",
    "    dgpr_vendors3['ms_websites_firm2'] = dgpr_vendors3['ms_websites_firm']**2\n",
    "    \n",
    "    # collapse (sum) hhi=ms_websites_firm2, by (date) fast\n",
    "    dgpr_vendors4 = dgpr_vendors3.groupby(['date'],as_index=False).agg(date=('date','first'),\n",
    "                                                                    hhi=('ms_websites_firm2','sum'))\n",
    "\n",
    "    # gen after=date>td(25may2018)\n",
    "    dgpr_vendors4['after']=np.where(dgpr_vendors4['date']>np.datetime64('2018-05-25'), 1,0 )\n",
    "    \n",
    "    # su date\n",
    "    # gen trend=(date-r(min)+1)/100\n",
    "    dgpr_vendors4['trend']=(dgpr_vendors4['date']- dgpr_vendors4['date'].min()+np.timedelta64(1, 'D'))/np.timedelta64(100, 'D')\n",
    "    \n",
    "    # su date if after==1\n",
    "    # gen trend_after=(date-r(min)+1)/100\n",
    "    dgpr_vendors4['trend_after']=0\n",
    "    dgpr_vendors4.loc[dgpr_vendors4['after']==1,'trend_after']=(dgpr_vendors4.loc[\n",
    "        dgpr_vendors4['after']==1,'date']-dgpr_vendors4.loc[dgpr_vendors4['after']==1,'date'].min()+\n",
    "                                                                np.timedelta64(1, 'D'))/np.timedelta64(100, 'D')\n",
    "    \n",
    "    # eststo m_requests_g: reg hhi trend after c.trend_after#c.after, robust\n",
    "    m_requests_g_nonGoogle = smf.ols(\"hhi ~ trend + after + trend_after*after\", data=dgpr_vendors4).fit(cov_type='HC1')\n",
    "    m_requests_g_nonGoogle.summary().tables[1]\n",
    "    result_for_nonGoogle = pd.read_html(m_requests_g_nonGoogle.summary().tables[1].as_html(), header=0, index_col=0)[0]\n",
    "    result_table[\"HHI without Google\"]=[result_for_nonGoogle.loc[\"after\",\"coef\"].round(3),\n",
    "                                        result_for_nonGoogle.loc[\"after\",\"std err\"].round(3),\n",
    "                             f\"{len(dgpr_vendors4)}\",round(dgpr_vendors4[dgpr_vendors4['after']==0][\"hhi\"].mean(),3) ]\n",
    "    \n",
    "    result=pd.DataFrame(result_table).set_index(\"row_name\")\n",
    "    result.index.name = None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ee7fedd-f5a8-4f20-8e13-da5af5999b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 4, but rank is 3\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:1832: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 4, but rank is 3\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHI all</th>\n",
       "      <th>HHI without Google</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <td>8.176</td>\n",
       "      <td>-1.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(std err)</th>\n",
       "      <td>9.221</td>\n",
       "      <td>1.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observations</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre-GDPR mean</th>\n",
       "      <td>950.82</td>\n",
       "      <td>68.458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              HHI all HHI without Google\n",
       "After           8.176             -1.576\n",
       "(std err)       9.221              1.129\n",
       "Observations       21                 21\n",
       "Pre-GDPR mean  950.82             68.458"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgpr_vendors=pd.read_stata(\"/Users/zyy219/Dropbox/Econometric/mksc.2021.1339/data/gdpr_vendors.dta\")\n",
    "\n",
    "dgpr_vendors = dgpr_vendors[(dgpr_vendors['date']<np.datetime64('2018-10-02')) & \n",
    "         (dgpr_vendors['date']>np.datetime64('2017-11-14'))]\n",
    "table7(dgpr_vendors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5699db3b-c540-4a0d-ac12-f7140bcce712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table8(dgpr_vendors):\n",
    "    # ------------------------------------------------\n",
    "    # This function will take dgpr_vendors dataset and output the table (8) to show the change in Market Structure and Number of Websites\n",
    "    # Inputs: \n",
    "    #    dgpr_vendors dataset: dataset\n",
    "    # Output: Table 8\n",
    "    # ---------------------------------------------------\n",
    "    result_table={}\n",
    "    result_table[\"row_name\"]=[\"Post X Google\",\"(std err)\",\"Post X Non-Google\",\"(std err)\",\n",
    "                              \"Observations\",\"R2\",\"Pre-GDPR Google\",\"Pre-GDPR non-Google\"]\n",
    "    # gen after=date>=td(25may2018)\n",
    "    dgpr_vendors['after']=np.where(dgpr_vendors['date']>np.datetime64('2018-05-25'), 1,0 )\n",
    "    # gen log_websites=log(1+tracker_firm_websites)\n",
    "    dgpr_vendors['log_websites']=np.log(1+dgpr_vendors['tracker_firm_websites'])\n",
    "    # gen google=tracker_firm==\"google\"\n",
    "    dgpr_vendors['google']=[1 if i else 0 for i in (dgpr_vendors['tracker_firm']=='google')]\n",
    "    # gen nongoogle=1-google\n",
    "    dgpr_vendors['nongoogle']=1-dgpr_vendors['google']\n",
    "    \n",
    "    # bys tracker_firm date: keep if _n==1\t\n",
    "    dgpr_vendors1=dgpr_vendors.groupby(['tracker_firm','date'],as_index=False).agg(date=('date','first'),\n",
    "                                                                    tracker_firm=('tracker_firm','first'),\n",
    "                                                                    ms_websites_firm=('ms_websites_firm','first'),\n",
    "                                                                    Google=('google','first'),\n",
    "                                                                    NonGoogle=('nongoogle','first'),\n",
    "                                                                    log_websites=('log_websites','first'),\n",
    "                                                                    Post=('after','first')) \n",
    "    \n",
    "    # gen trend=(date-`r(min)'+1)/100\n",
    "    dgpr_vendors1['trend']=(dgpr_vendors1['date']- dgpr_vendors1['date'].min()+np.timedelta64(1, 'D'))/np.timedelta64(100, 'D')\n",
    "    \n",
    "    # su date if after==1\n",
    "    # gen trend_after=(date-`r(min)'+1)/100\n",
    "    dgpr_vendors1['trend_after']=0\n",
    "    dgpr_vendors1.loc[dgpr_vendors1['Post']==1,'trend_after']=(dgpr_vendors1.loc[\n",
    "        dgpr_vendors1['Post']==1,'date']-dgpr_vendors1.loc[dgpr_vendors1['Post']==1,'date'].min()+\n",
    "                                                                np.timedelta64(1, 'D'))/np.timedelta64(100, 'D')\n",
    "    \n",
    "    # egen tf=group(tracker_firm)\n",
    "    dgpr_vendors1['tf']=dgpr_vendors1.groupby('tracker_firm').ngroup()\n",
    "    \n",
    "    \n",
    "    dgpr_vendors1['trend_google']=dgpr_vendors1['trend']*dgpr_vendors1['Google']\n",
    "    dgpr_vendors1['after_google']=dgpr_vendors1['Post']*dgpr_vendors1['Google']\n",
    "    dgpr_vendors1['trend_after_after_google']=dgpr_vendors1['trend_after']*dgpr_vendors1['Post']*dgpr_vendors1['Google']\n",
    "    dgpr_vendors1['trend_nongoogle']=dgpr_vendors1['trend']*dgpr_vendors1['NonGoogle']\n",
    "    dgpr_vendors1['after_nongoogle']=dgpr_vendors1['Post']*dgpr_vendors1['NonGoogle']\n",
    "    dgpr_vendors1['trend_after_after_nongoogle']=dgpr_vendors1['trend_after']*dgpr_vendors1['Post']*dgpr_vendors1['NonGoogle']\n",
    "\n",
    "    \n",
    "    # websites\n",
    "    exog_variables_websites = ['trend_google','after_google','trend_after_after_google','trend_nongoogle',\n",
    "                                                     'after_nongoogle','trend_after_after_nongoogle']\n",
    "    endog_variable_websites = ['log_websites']\n",
    "    cats_websites = pd.DataFrame({'tf': pd.Categorical(dgpr_vendors1['tf'])})\n",
    "    exog_websites = sm.tools.tools.add_constant(dgpr_vendors1[exog_variables_websites])\n",
    "    endog_websites =dgpr_vendors1[endog_variable_websites]\n",
    "    model_websites = absorbing.AbsorbingLS(endog_websites, exog_websites, absorb= cats_websites, drop_absorbed=False)\n",
    "    model_res_websites = model_websites.fit(cov_type= 'clustered',clusters =dgpr_vendors1['tf'],debiased=True)\n",
    "    \n",
    "    websites_summary_estimate= pd.read_html(model_res_websites.summary.tables[0].as_html(), header=0, index_col=0)[0]\n",
    "    websites_summary_table = pd.read_html(model_res_websites.summary.tables[1].as_html(), header=0, index_col=0)[0]\n",
    "    website_p_value_afterGoogle = float(websites_summary_table.loc['after_google','P-value'])\n",
    "    website_p_value_afternonGoogle = float(websites_summary_table.loc['after_nongoogle','P-value'])\n",
    "    result_table[\"No.websites\"]=[f\"{websites_summary_table.loc['after_google','Parameter'].round(4)}{'***' if (website_p_value_afterGoogle <0.01) else ( '**' if website_p_value_afterGoogle <0.05 else ('*' if website_p_value_afterGoogle  <0.1 else ''))}\",\n",
    "                    websites_summary_table.loc[\"after_google\",\"Std. Err.\"].round(4),\n",
    "                    f\"{websites_summary_table.loc['after_nongoogle','Parameter'].round(4)}{'***' if (website_p_value_afternonGoogle <0.01) else ( '**' if website_p_value_afternonGoogle<0.05 else ('*' if website_p_value_afternonGoogle  <0.1 else ''))}\",\n",
    "                    websites_summary_table.loc[\"after_nongoogle\",\"Std. Err.\"].round(4),\n",
    "                    dgpr_vendors1.shape[0],\n",
    "                    websites_summary_estimate.iloc[0,2],\n",
    "                    round(np.mean(dgpr_vendors1['log_websites'][(dgpr_vendors1['Post'] == 0) & (dgpr_vendors1['Google']==1)]),4),\n",
    "                    round(np.mean(dgpr_vendors1['log_websites'][(dgpr_vendors1['Post'] == 0) & (dgpr_vendors1['NonGoogle']==0)]),4)]\n",
    "    \n",
    "    # Market Shares\n",
    "    exog_variables_ms = ['trend_google','after_google','trend_after_after_google','trend_nongoogle',\n",
    "                                                     'after_nongoogle','trend_after_after_nongoogle']\n",
    "    endog_variable_ms = ['ms_websites_firm']\n",
    "    cats_ms = pd.DataFrame({'tf': pd.Categorical(dgpr_vendors1['tf'])})\n",
    "    exog_ms = sm.tools.tools.add_constant(dgpr_vendors1[exog_variables_ms])\n",
    "    endog_ms =dgpr_vendors1[endog_variable_ms]\n",
    "    model_ms = absorbing.AbsorbingLS(endog_ms, exog_ms, absorb= cats_ms, drop_absorbed=False)\n",
    "    model_res_ms = model_ms.fit(cov_type= 'clustered',clusters =dgpr_vendors1['tf'],debiased=True)\n",
    "\n",
    "    ms_summary_estimate= pd.read_html(model_res_ms.summary.tables[0].as_html(), header=0, index_col=0)[0]\n",
    "    ms_summary_table = pd.read_html(model_res_ms.summary.tables[1].as_html(), header=0, index_col=0)[0]\n",
    "    ms_p_value_afterGoogle = float(ms_summary_table.loc['after_google','P-value'])\n",
    "    ms_p_value_afternonGoogle = float(ms_summary_table.loc['after_nongoogle','P-value'])\n",
    "    result_table[\"Market Shares\"]=[f\"{ms_summary_table.loc['after_google','Parameter'].round(4)}{ '***' if (ms_p_value_afterGoogle <0.01) else ( '**' if ms_p_value_afterGoogle<0.05 else ('*' if ms_p_value_afterGoogle <0.1 else ''))}\",\n",
    "                ms_summary_table.loc[\"after_google\",\"Std. Err.\"].round(4),\n",
    "                f\"{ms_summary_table.loc['after_nongoogle','Parameter'].round(4)}{ '***' if (ms_p_value_afternonGoogle <0.01) else ( '**' if ms_p_value_afternonGoogle<0.05 else ('*' if ms_p_value_afternonGoogle <0.1 else ''))}\",\n",
    "                ms_summary_table.loc[\"after_nongoogle\",\"Std. Err.\"].round(4),\n",
    "                dgpr_vendors1.shape[0],\n",
    "                ms_summary_estimate.iloc[0,2],\n",
    "                round(np.mean(dgpr_vendors1['ms_websites_firm'][(dgpr_vendors1['Post'] == 0) & (dgpr_vendors1['Google']==1)]),4),\n",
    "                round(np.mean(dgpr_vendors1['ms_websites_firm'][(dgpr_vendors1['Post'] == 0) & (dgpr_vendors1['NonGoogle']==1)]),4)]\n",
    "    \n",
    "    result=pd.DataFrame(result_table).set_index(\"row_name\")\n",
    "    result.index.name = None\n",
    "    return result     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f600c05-4732-4ee4-b817-65bd1607c8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.websites</th>\n",
       "      <th>Market Shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Post X Google</th>\n",
       "      <td>-0.0192***</td>\n",
       "      <td>0.161***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(std err)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post X Non-Google</th>\n",
       "      <td>0.0013</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(std err)</th>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observations</th>\n",
       "      <td>1329132</td>\n",
       "      <td>1329132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre-GDPR Google</th>\n",
       "      <td>13.1587</td>\n",
       "      <td>29.7036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre-GDPR non-Google</th>\n",
       "      <td>13.1587</td>\n",
       "      <td>0.0011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    No.websites Market Shares\n",
       "Post X Google        -0.0192***      0.161***\n",
       "(std err)                   0.0           0.0\n",
       "Post X Non-Google        0.0013          -0.0\n",
       "(std err)                0.0011           0.0\n",
       "Observations            1329132       1329132\n",
       "R2                       0.9232        0.9996\n",
       "Pre-GDPR Google         13.1587       29.7036\n",
       "Pre-GDPR non-Google     13.1587        0.0011"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table8(dgpr_vendors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abc6778d-39c8-4ab3-b676-306e20cd0c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table9(dgpr_vendors_cat):\n",
    "    # ------------------------------------------------\n",
    "    # This function will take dgpr_vendors dataset and output the table (9) to show the change in Number of Websites based on different Submarket\n",
    "    # Inputs: \n",
    "    #    dgpr_vendors dataset: dataset\n",
    "    # Output: Table 9\n",
    "    # ---------------------------------------------------\n",
    "    categories=[(\"audio_video_player\",\"Video\"),(\"advertising\",\"Advertising\"),(\"site_analytics\",\"Analytics\"),\n",
    "                (\"cdn\",\"CDN/API\"),(\"unknown\",\"Other\")]\n",
    "    dgpr_vendors_cat['trend_google']=dgpr_vendors_cat['trend']*dgpr_vendors_cat['google']\n",
    "    dgpr_vendors_cat['trend_nongoogle']=dgpr_vendors_cat['trend']*dgpr_vendors_cat['nongoogle']\n",
    "    dgpr_vendors_cat['trend_after_after_google']=dgpr_vendors_cat['trend_after']*dgpr_vendors_cat['after']*dgpr_vendors_cat['google']\n",
    "    dgpr_vendors_cat['trend_after_after_nongoogle']=dgpr_vendors_cat['trend_after']*dgpr_vendors_cat['after']*dgpr_vendors_cat['nongoogle']\n",
    "    dgpr_vendors_cat['after_google']=dgpr_vendors_cat['after']*dgpr_vendors_cat['google']\n",
    "    dgpr_vendors_cat['after_nongoogle']=dgpr_vendors_cat['after']*dgpr_vendors_cat['nongoogle']\n",
    "    result_table={}\n",
    "    result_table[\"row_name\"]=[\"Post X Google\",\"(std err)\",\"Post X Non-Google\",\"(std err)\",\n",
    "                          \"Observations\",\"R2\",\"Pre-GDPR Google\",\"Pre-GDPR non-Google\"]\n",
    "    for (a,b) in categories:\n",
    "        dgpr_vendors_cat_detail = dgpr_vendors_cat[dgpr_vendors_cat['category_id']==a]\n",
    "        exog_variables = ['google','nongoogle','trend_google','trend_nongoogle',\n",
    "                                                 'trend_after_after_google','trend_after_after_nongoogle',\n",
    "                                                  'after_google','after_nongoogle']\n",
    "        endog_variable = ['log_websites']\n",
    "        cats= pd.DataFrame({'tf': pd.Categorical(dgpr_vendors_cat_detail['tf'])})\n",
    "        exog = sm.tools.tools.add_constant(dgpr_vendors_cat_detail[exog_variables])\n",
    "        endog =dgpr_vendors_cat_detail[endog_variable]\n",
    "        model = absorbing.AbsorbingLS(endog, exog, absorb= cats, drop_absorbed=True)\n",
    "        model_res = model.fit(cov_type= 'clustered',clusters =dgpr_vendors_cat_detail['tf'],debiased=True)\n",
    "        \n",
    "        summary_estimate= pd.read_html(model_res.summary.tables[0].as_html(), header=0, index_col=0)[0]\n",
    "        summary_table = pd.read_html(model_res.summary.tables[1].as_html(), header=0, index_col=0)[0]\n",
    "        p_value_afterGoogle = float(summary_table.loc['after_google','P-value'])\n",
    "        p_value_afternonGoogle = float(summary_table.loc['after_nongoogle','P-value'])\n",
    "        \n",
    "        result_table[b]=[f\"{summary_table.loc['after_google','Parameter'].round(6)}{ '***' if (p_value_afterGoogle <0.01) else ( '**' if p_value_afterGoogle<0.05 else ('*' if p_value_afterGoogle <0.1 else ''))}\",\n",
    "            summary_table.loc[\"after_google\",\"Std. Err.\"].round(6),\n",
    "            f\"{summary_table.loc['after_nongoogle','Parameter'].round(6)}{ '***' if (p_value_afternonGoogle <0.01) else ( '**' if p_value_afternonGoogle<0.05 else ('*' if p_value_afternonGoogle <0.1 else ''))}\",\n",
    "            summary_table.loc[\"after_nongoogle\",\"Std. Err.\"].round(6),\n",
    "            dgpr_vendors_cat_detail.shape[0],\n",
    "            round(float(summary_estimate.iloc[0,2]),6),\n",
    "            round(np.mean(dgpr_vendors_cat_detail['log_websites'][(dgpr_vendors_cat_detail['after'] == 0) & (dgpr_vendors_cat_detail['google']==1)]),6),\n",
    "            round(np.mean(dgpr_vendors_cat_detail['log_websites'][(dgpr_vendors_cat_detail['after'] == 0) & (dgpr_vendors_cat_detail['nongoogle']==1)]),6)]\n",
    "\n",
    "    result=pd.DataFrame(result_table).set_index(\"row_name\")\n",
    "    result.index.name = None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93150d3f-a02b-4057-94e9-b58291160cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "/var/folders/8k/fs12fbvs52dfyf4blh3m7gbs29v449/T/ipykernel_2041/1633917560.py:29: AbsorbingEffectWarning: \n",
      "Variables have been fully absorbed and have removed from the regression:\n",
      "\n",
      "google, nongoogle\n",
      "\n",
      "  model_res = model.fit(cov_type= 'clustered',clusters =dgpr_vendors_cat_detail['tf'],debiased=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Analytics</th>\n",
       "      <th>CDN/API</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Post X Google</th>\n",
       "      <td>-0.0312***</td>\n",
       "      <td>-0.0265***</td>\n",
       "      <td>-0.0146***</td>\n",
       "      <td>-0.0105***</td>\n",
       "      <td>-0.0057***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(std err)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post X Non-Google</th>\n",
       "      <td>-0.0006</td>\n",
       "      <td>-0.0233**</td>\n",
       "      <td>-0.0099**</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(std err)</th>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observations</th>\n",
       "      <td>20840</td>\n",
       "      <td>20840</td>\n",
       "      <td>20840</td>\n",
       "      <td>20840</td>\n",
       "      <td>20840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.9893</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>0.9864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre-GDPR Google</th>\n",
       "      <td>10.197235</td>\n",
       "      <td>12.287216</td>\n",
       "      <td>11.480545</td>\n",
       "      <td>11.726396</td>\n",
       "      <td>6.707033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre-GDPR non-Google</th>\n",
       "      <td>0.101116</td>\n",
       "      <td>2.257271</td>\n",
       "      <td>0.928712</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>0.405099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Video Advertising   Analytics     CDN/API  \\\n",
       "Post X Google        -0.0312***  -0.0265***  -0.0146***  -0.0105***   \n",
       "(std err)                   0.0         0.0         0.0         0.0   \n",
       "Post X Non-Google       -0.0006   -0.0233**   -0.0099**     -0.0012   \n",
       "(std err)                0.0021      0.0111      0.0049      0.0008   \n",
       "Observations              20840       20840       20840       20840   \n",
       "R2                       0.9889       0.984      0.9893      0.9987   \n",
       "Pre-GDPR Google       10.197235   12.287216   11.480545   11.726396   \n",
       "Pre-GDPR non-Google    0.101116    2.257271    0.928712    0.188791   \n",
       "\n",
       "                          Other  \n",
       "Post X Google        -0.0057***  \n",
       "(std err)                   0.0  \n",
       "Post X Non-Google        -0.006  \n",
       "(std err)                0.0042  \n",
       "Observations              20840  \n",
       "R2                       0.9864  \n",
       "Pre-GDPR Google        6.707033  \n",
       "Pre-GDPR non-Google    0.405099  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgpr_vendors_cat = pd.read_stata('/Users/zyy219/Dropbox/Econometric/mksc.2021.1339/data/gdpr_vendors_cat.dta')\n",
    "dgpr_vendors_cat = dgpr_vendors_cat[(dgpr_vendors_cat['date']<np.datetime64('2018-10-02')) & \n",
    "         (dgpr_vendors_cat['date']>np.datetime64('2017-11-14'))]\n",
    "table9(dgpr_vendors_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dbca1ea-c3c0-4145-b9a7-811c8ae1650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table10(dgpr_vendors_cat):\n",
    "    # ------------------------------------------------\n",
    "    # This function will take dgpr_vendors dataset and output the table (10) to show the change in Market Shares based on different Submarket\n",
    "    # Inputs: \n",
    "    #    dgpr_vendors dataset: dataset\n",
    "    # Output: Table 10\n",
    "    # ---------------------------------------------------\n",
    "    \n",
    "    categories=[(\"audio_video_player\",\"Video\"),(\"advertising\",\"Advertising\"),(\"site_analytics\",\"Analytics\"),\n",
    "                (\"cdn\",\"CDN/API\"),(\"unknown\",\"Other\")]\n",
    "    dgpr_vendors_cat['trend_google']=dgpr_vendors_cat['trend']*dgpr_vendors_cat['google']\n",
    "    dgpr_vendors_cat['trend_nongoogle']=dgpr_vendors_cat['trend']*dgpr_vendors_cat['nongoogle']\n",
    "    dgpr_vendors_cat['trend_after_after_google']=dgpr_vendors_cat['trend_after']*dgpr_vendors_cat['after']*dgpr_vendors_cat['google']\n",
    "    dgpr_vendors_cat['trend_after_after_nongoogle']=dgpr_vendors_cat['trend_after']*dgpr_vendors_cat['after']*dgpr_vendors_cat['nongoogle']\n",
    "    dgpr_vendors_cat['after_google']=dgpr_vendors_cat['after']*dgpr_vendors_cat['google']\n",
    "    dgpr_vendors_cat['after_nongoogle']=dgpr_vendors_cat['after']*dgpr_vendors_cat['nongoogle']\n",
    "    result_table={}\n",
    "    result_table[\"row_name\"]=[\"Post X Google\",\"(std err)\",\"Post X Non-Google\",\"(std err)\",\n",
    "                          \"Observations\",\"R2\",\"Pre-GDPR Google\",\"Pre-GDPR non-Google\"]\n",
    "    for (a,b) in categories:\n",
    "        dgpr_vendors_cat_detail = dgpr_vendors_cat[dgpr_vendors_cat['category_id']==a]\n",
    "        exog_variables = ['google','nongoogle','trend_google','trend_nongoogle',\n",
    "                                                 'trend_after_after_google','trend_after_after_nongoogle',\n",
    "                                                  'after_google','after_nongoogle']\n",
    "        endog_variable = ['ms_websites_firm']\n",
    "        cats= pd.DataFrame({'tf': pd.Categorical(dgpr_vendors_cat_detail['tf'])})\n",
    "        exog = sm.tools.tools.add_constant(dgpr_vendors_cat_detail[exog_variables])\n",
    "        endog =dgpr_vendors_cat_detail[endog_variable]\n",
    "        model = absorbing.AbsorbingLS(endog, exog, absorb= cats, drop_absorbed=True)\n",
    "        model_res = model.fit(cov_type= 'clustered',clusters =dgpr_vendors_cat_detail['tf'],debiased=True)\n",
    "        \n",
    "        summary_estimate= pd.read_html(model_res.summary.tables[0].as_html(), header=0, index_col=0)[0]\n",
    "        summary_table = pd.read_html(model_res.summary.tables[1].as_html(), header=0, index_col=0)[0]\n",
    "        p_value_afterGoogle = float(summary_table.loc['after_google','P-value'])\n",
    "        p_value_afternonGoogle = float(summary_table.loc['after_nongoogle','P-value'])\n",
    "        \n",
    "        result_table[b]=[f\"{summary_table.loc['after_google','Parameter'].round(6)}{ '***' if (p_value_afterGoogle <0.01) else ( '**' if p_value_afterGoogle<0.05 else ('*' if p_value_afterGoogle <0.1 else ''))}\",\n",
    "            summary_table.loc[\"after_google\",\"Std. Err.\"].round(6),\n",
    "            f\"{summary_table.loc['after_nongoogle','Parameter'].round(6)}{ '***' if (p_value_afternonGoogle <0.01) else ( '**' if p_value_afternonGoogle<0.05 else ('*' if p_value_afternonGoogle <0.1 else ''))}\",\n",
    "            summary_table.loc[\"after_nongoogle\",\"Std. Err.\"].round(6),\n",
    "            dgpr_vendors_cat_detail.shape[0],\n",
    "            round(float(summary_estimate.iloc[0,2]),6),\n",
    "            round(np.mean(dgpr_vendors_cat_detail['ms_websites_firm'][(dgpr_vendors_cat_detail['after'] == 0) & (dgpr_vendors_cat_detail['google']==1)]),6),\n",
    "            round(np.mean(dgpr_vendors_cat_detail['ms_websites_firm'][(dgpr_vendors_cat_detail['after'] == 0) & (dgpr_vendors_cat_detail['nongoogle']==1)]),6)]\n",
    "\n",
    "    result=pd.DataFrame(result_table).set_index(\"row_name\")\n",
    "    result.index.name = None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb9f8ca1-b332-4614-9e64-a15d3915e3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "/var/folders/8k/fs12fbvs52dfyf4blh3m7gbs29v449/T/ipykernel_2041/2402800178.py:30: AbsorbingEffectWarning: \n",
      "Variables have been fully absorbed and have removed from the regression:\n",
      "\n",
      "google, nongoogle\n",
      "\n",
      "  model_res = model.fit(cov_type= 'clustered',clusters =dgpr_vendors_cat_detail['tf'],debiased=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Analytics</th>\n",
       "      <th>CDN/API</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Post X Google</th>\n",
       "      <td>-1.6969***</td>\n",
       "      <td>0.4869***</td>\n",
       "      <td>0.4948***</td>\n",
       "      <td>-0.5692***</td>\n",
       "      <td>-0.029***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(std err)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post X Non-Google</th>\n",
       "      <td>0.0016</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>2.8e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(std err)</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observations</th>\n",
       "      <td>20840</td>\n",
       "      <td>20840</td>\n",
       "      <td>20840</td>\n",
       "      <td>20840</td>\n",
       "      <td>20840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre-GDPR Google</th>\n",
       "      <td>77.04818</td>\n",
       "      <td>27.228949</td>\n",
       "      <td>39.232204</td>\n",
       "      <td>70.080956</td>\n",
       "      <td>1.192459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre-GDPR non-Google</th>\n",
       "      <td>0.022048</td>\n",
       "      <td>0.069905</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>0.028741</td>\n",
       "      <td>0.094916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Video Advertising  Analytics     CDN/API      Other\n",
       "Post X Google        -1.6969***   0.4869***  0.4948***  -0.5692***  -0.029***\n",
       "(std err)                   0.0         0.0        0.0         0.0        0.0\n",
       "Post X Non-Google        0.0016     -0.0005    -0.0005      0.0005    2.8e-05\n",
       "(std err)                 0.001      0.0007     0.0007      0.0006     0.0016\n",
       "Observations              20840       20840      20840       20840      20840\n",
       "R2                       0.9997      0.9991     0.9986      0.9999     0.9954\n",
       "Pre-GDPR Google        77.04818   27.228949  39.232204   70.080956   1.192459\n",
       "Pre-GDPR non-Google    0.022048    0.069905   0.058374    0.028741   0.094916"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table10(dgpr_vendors_cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb4f00d-1dfd-486f-a5b8-a5b7b49482ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
